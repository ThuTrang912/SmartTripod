Để tích hợp YOLOv5 vào ứng dụng Flutter và sử dụng nó để nhận diện hình ảnh, chúng ta cần một vài bước chuẩn bị:

1.Tích hợp YOLOv5 vào Flutter: Flutter không thể trực tiếp chạy mô hình YOLOv5 vì YOLOv5 thường chạy trên Python. Do đó, bạn cần một dịch vụ backend (REST API) để xử lý mô hình YOLOv5.
2.Tạo backend service: Sử dụng Flask hoặc FastAPI để tạo API nhận hình ảnh từ Flutter, xử lý bằng YOLOv5 và trả về kết quả.
3.Gửi hình ảnh từ Flutter đến API: Sau khi xử lý hình ảnh, gửi hình ảnh đến API và nhận kết quả nhận diện.
4.Hiển thị kết quả trong Flutter: Dựa vào kết quả nhận diện, hiển thị lát bánh mì (hoặc bất kỳ biểu tượng nào bạn muốn) trên ảnh.



------------------------------------------------------------------------------------------------------------------------------------

1.Backend API (Python với Flask và YOLOv5)
Trước tiên, chúng ta cần tạo một API sử dụng Flask để xử lý YOLOv5. Giả sử bạn đã cài đặt YOLOv5 và các thư viện cần thiết.

Flask API với YOLOv5

# app.py

from flask import Flask, request, jsonify
import torch
from PIL import Image
import io

app = Flask(__name__)

# Load YOLOv5 model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s')

@app.route('/detect', methods=['POST'])
def detect():
    if 'image' not in request.files:
        return jsonify({'error': 'No image file'}), 400

    image_file = request.files['image']
    image_bytes = image_file.read()
    image = Image.open(io.BytesIO(image_bytes))

    # Perform inference
    results = model(image)
    detections = results.pandas().xyxy[0].to_json(orient="records")
    
    return jsonify({'detections': detections})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
Chạy Flask API:




sh

python app.py




2.Flutter: Gửi hình ảnh đến API và nhận kết quả
Cập nhật IdentifiedObject để gửi hình ảnh đã cắt đến API và xử lý kết quả.

Flutter Code
dart

import 'dart:io';
import 'dart:typed_data';
import 'dart:ui' as ui;
import 'package:flutter/material.dart';
import 'package:camera/camera.dart';
import 'package:http/http.dart' as http;
import 'dart:convert';
import 'record_camera.dart';
import 'dart:ui' show lerpDouble;

class IdentifiedObject extends StatefulWidget {
  final String imagePath;

  IdentifiedObject(
      {Key? key, required this.imagePath, required CameraDescription camera})
      : super(key: key);

  @override
  _IdentifiedObjectState createState() => _IdentifiedObjectState();
}

class _IdentifiedObjectState extends State<IdentifiedObject> {
  Offset _initialPosition = Offset(100, 100);
  Offset _currentPosition = Offset(100, 100);
  Size _currentSize = Size(200, 200);
  late List<CameraDescription> cameras;

  GlobalKey _imageKey = GlobalKey();

  @override
  void initState() {
    super.initState();
    _initialPosition = Offset(100, 100);
    _currentPosition = Offset(100, 100);
    _currentSize = Size(200, 200);
    _initializeCameras();
  }

  Future<void> _initializeCameras() async {
    try {
      cameras = await availableCameras();
    } catch (e) {
      print('Error initializing cameras: $e');
    }
  }

  void _onPanStart(DragStartDetails details) {
    setState(() {
      _initialPosition = details.localPosition;
      _currentPosition = details.localPosition;
      _currentSize = Size.zero;
    });
  }

  void _onPanUpdate(DragUpdateDetails details) {
    setState(() {
      _currentPosition = details.localPosition;
      _currentSize = Size(
        (_currentPosition.dx - _initialPosition.dx).abs(),
        (_currentPosition.dy - _initialPosition.dy).abs(),
      );
    });
  }

  Future<void> _sendImageForDetection() async {
    if (_currentSize != Size.zero && cameras.isNotEmpty) {
      RenderBox box = _imageKey.currentContext!.findRenderObject() as RenderBox;
      double imageWidth = box.size.width;
      double imageHeight = box.size.height;

      ui.PictureRecorder recorder = ui.PictureRecorder();
      Canvas canvas = Canvas(recorder);

      ui.Image originalImage = await _loadImage(widget.imagePath);
      paintImage(
        canvas: canvas,
        rect: Rect.fromLTWH(0, 0, imageWidth, imageHeight),
        image: originalImage,
        fit: BoxFit.cover,
      );

      ui.Image fullImage = await recorder.endRecording().toImage(
            imageWidth.toInt(),
            imageHeight.toInt(),
          );

      ui.Image croppedImage = await _cropImage(
        fullImage,
        _initialPosition.dx,
        _initialPosition.dy,
        _currentSize.width,
        _currentSize.height,
      );

      ByteData byteData =
          await croppedImage.toByteData(format: ui.ImageByteFormat.png) ??
              ByteData(0);
      Uint8List imageBytes = byteData.buffer.asUint8List();

      final croppedImagePath = '${widget.imagePath}_cropped.png';
      await File(croppedImagePath).writeAsBytes(imageBytes);

      // Send cropped image to YOLOv5 API for detection
      var request = http.MultipartRequest(
        'POST',
        Uri.parse('http://your_backend_api/detect'),
      );
      request.files.add(
        http.MultipartFile.fromBytes(
          'image',
          imageBytes,
          filename: 'cropped.png',
        ),
      );
      var response = await request.send();
      var responseData = await response.stream.bytesToString();

      var detections = json.decode(responseData)['detections'];

      // Check if object is detected
      if (detections.isNotEmpty) {
        // Redirect to recognized camera page with detected coordinates
        await Navigator.pushReplacement(
          context,
          MaterialPageRoute(
            builder: (context) => RecordCamera(
              camera: cameras[0],
              croppedImagePath: croppedImagePath,
            ),
          ),
        );
      } else {
        // Show error message if no object detected
        showDialog(
          context: context,
          builder: (context) => AlertDialog(
            title: Text('No Object Detected'),
            content: Text('No objects were detected in the selected area.'),
            actions: [
              TextButton(
                child: Text('OK'),
                onPressed: () {
                  Navigator.of(context).pop();
                },
              ),
            ],
          ),
        );
      }
    } else {
      print('Cameras not available or image size is zero');
    }
  }

  Future<ui.Image> _loadImage(String path) async {
    final data = await File(path).readAsBytes();
    return decodeImageFromList(data);
  }

  Future<ui.Image> _cropImage(
      ui.Image image, double x, double y, double width, double height) async {
    final recorder = ui.PictureRecorder();
    final canvas = Canvas(recorder);
    final paint = Paint();

    canvas.drawImageRect(
      image,
      Rect.fromLTWH(x, y, width, height),
      Rect.fromLTWH(0, 0, width, height),
      paint,
    );

    return await recorder.endRecording().toImage(width.toInt(), height.toInt());
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: Color(0xFF333333),
      appBar: AppBar(
        backgroundColor: Color(0xFF333333),
        leading: IconButton(
          icon: Icon(Icons.arrow_back, color: Colors.white),
          onPressed: () {
            Navigator.of(context).pop();
          },
        ),
      ),
      body: Stack(
        children: [
          RepaintBoundary(
            key: _imageKey,
            child: Container(
              width: double.infinity,
              height: double.infinity,
              color: Color(0xFF333333),
              child: GestureDetector(
                onPanStart: _onPanStart,
                onPanUpdate: _onPanUpdate,
                child: Image.file(
                  File(widget.imagePath),
                  fit: BoxFit.cover,
                ),
              ),
            ),
          ),
          Positioned(
            top: _initialPosition.dy,
            left: _initialPosition.dx,
            width: _currentSize.width,
            height: _currentSize.height,
            child: Container(
              decoration: BoxDecoration(
                border: Border.all(color: Colors.red, width: 2),
              ),
            ),
          ),
          Positioned(
            bottom: 0,
            left: 0,
            right: 0,
            child: Container(
              height: 60,
              color: Color(0xFF333333),
              child: Row(
                mainAxisAlignment: MainAxisAlignment.spaceAround,
                children: [
                  IconButton(
                    icon: Icon(Icons.check),
                    color: Colors.white,
                    onPressed: _sendImageForDetection,
                  ),
                ],
              ),
            ),
          ),
        ],
      ),
    );
  }
}
Giải thích:
Flask API: Flask API sẽ nhận hình ảnh từ Flutter, xử lý bằng YOLOv5 và trả về kết quả nhận diện.
Flutter:
Gửi hình ảnh đã cắt đến API.
Nhận kết quả và hiển thị lát bánh mì nếu đối tượng được nhận diện.
Chuyển hướng đến trang tiếp theo nếu có đối tượng được nhận diện.
Lưu ý rằng bạn cần cập nhật URL của API (http://your_backend_api/detect) với địa chỉ thực tế của backend bạn đã triển khai.